{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from data import rxn\n",
    "from data_process import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from models import *\n",
    "import dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--epochs', type=int, default=50, help='Number of epochs to train.')\n",
    "parser.add_argument('--lr', type=float, default = 0.001, help='learning rate.')\n",
    "parser.add_argument('--model', type=str, default=\"GNN\", help = 'MLP, GNN')\n",
    "parser.add_argument('--dev', type=int, default=7)\n",
    "parser.add_argument('--seed', type=int, default=42)\n",
    "parser.add_argument('--batch_size', type=int, default=256)\n",
    "parser.add_argument('--data_path', type=str)\n",
    "\n",
    "args = parser.parse_args([])\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda:\"+str(args.dev) if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./normal_ids.pkl', 'rb') as file:\n",
    "    train_ids = pickle.load(file)\n",
    "with open('./train_uncertain_ids.pkl', 'rb') as file:\n",
    "    uncertain_ids = pickle.load(file)\n",
    "with open('./test_clean_ids.pkl', 'rb') as file:\n",
    "    test_ids = pickle.load(file)\n",
    "with open('./test_uncertain_ids.pkl', 'rb') as file:\n",
    "    test_u_ids = pickle.load(file)\n",
    "\n",
    "data_processer = data_process(args.data_path)\n",
    "\n",
    "train_ids = data_processer.load_data(train_ids)\n",
    "uncertain_data = data_processer.load_data(uncertain_ids)\n",
    "test_u_data = data_processer.load_data(test_u_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_ids['yields'].mean()\n",
    "std = train_ids['yields'].std()\n",
    "input_dim = train_ids['features'].shape[1]\n",
    "def norm_label(labels):\n",
    "    return (labels - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feas_ds(Dataset):\n",
    "    def __init__(self, X_f, Y):\n",
    "        \"\"\"\n",
    "        X: feature\n",
    "        Y: yields\n",
    "        \"\"\"\n",
    "        self.X_f = X_f\n",
    "        self.Y = Y\n",
    "    def __len__(self):\n",
    "        return self.Y.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return  (self.X_f[idx][0], self.Y[idx])\n",
    "\n",
    "class graph_ds(Dataset):\n",
    "    def __init__(self, X_g, Y):\n",
    "        \"\"\"\n",
    "        X: feature\n",
    "        Y: yields\n",
    "        \"\"\"\n",
    "        self.X_g = np.array(X_g)\n",
    "        self.Y = Y\n",
    "    def __len__(self):\n",
    "        return self.Y.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # print(self.X_g[idx])\n",
    "        g1 = self.X_g[idx][0]\n",
    "        g2 = self.X_g[idx][1]\n",
    "        g3 = self.X_g[idx][2]\n",
    "        return  (g1, g2, g3, self.Y[idx])\n",
    "    \n",
    "def collate_reaction(batch):\n",
    "    batchdata = list(map(list, zip(*batch)))\n",
    "    gs = [dgl.batch(s) for s in batchdata[:3]]\n",
    "    labels = torch.FloatTensor(batchdata[-1])\n",
    "    return gs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.model == 'MLP':\n",
    "    train_loader = DataLoader(feas_ds(train_ids['features'], train_ids['yields']), \\\n",
    "                                  batch_size=256)\n",
    "    test_u_loader = DataLoader(feas_ds(test_u_data['features'], test_u_data['yields']), \\\n",
    "                                  batch_size=256)\n",
    "    model = MLP(input_dim,1024,6)\n",
    "\n",
    "else:\n",
    "    train_loader = DataLoader(graph_ds(train_ids['graphs'], train_ids['yields']), \\\n",
    "                                  batch_size=256, collate_fn=collate_reaction)\n",
    "    test_u_loader = DataLoader(graph_ds(test_u_data['graphs'], test_u_data['yields']), \\\n",
    "                                  batch_size=256, collate_fn=collate_reaction)\n",
    "    model = reactionMPNN(11,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckptpath = './logs/trained_{}.ckpt'.format(args.model)\n",
    "optimizer =torch.optim.AdamW(model.parameters(), lr = args.lr)\n",
    "best_loss = 12345\n",
    "model.to(device)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "for epoch in tqdm(range(args.epochs)):\n",
    "    train_loss = 0\n",
    "    for datas, label in train_loader:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        if args.model == \"MLP\":\n",
    "            datas = datas.to(torch.float32).to(device)\n",
    "        else:\n",
    "            datas  = [graph.to(device) for graph in datas]\n",
    "        label = norm_label(label).to(device).reshape(-1, 1)\n",
    "        out = model(datas)\n",
    "        loss = criterion(out,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.detach().cpu().numpy()\n",
    "    if train_loss<best_loss:\n",
    "        torch.save(model.state_dict(), ckptpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "def valid(model, data_loader):\n",
    "    model.eval()\n",
    "    Ys, Y_hats = [], []\n",
    "    with torch.no_grad():\n",
    "        for xs, ys in data_loader:\n",
    "            if args.model == \"MLP\":\n",
    "                xs = xs.to(torch.float32).to(device)\n",
    "            else:\n",
    "                xs  = [graph.to(device) for graph in xs]\n",
    "            ys = ys.reshape(-1, 1).numpy()\n",
    "            out = model(xs).detach().to(\"cpu\").numpy()\n",
    "            Ys.append(ys)\n",
    "            Y_hats.append(out)\n",
    "    Ys = np.concatenate(Ys, axis=0) * std + mean\n",
    "    Y_hats = np.concatenate(Y_hats, axis=0) * std + mean\n",
    "    r2 = r2_score(Ys, Y_hats)\n",
    "    mae = mean_absolute_error(Ys, Y_hats)\n",
    "    rmse = mean_squared_error(Ys, Y_hats, squared=False)\n",
    "    return (r2, mae, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(ckptpath, map_location=device))\n",
    "model = model.to(device)\n",
    "valid(model, test_u_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ehr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
